# Cronograma de Pesquisa

Plano de execução da pesquisa sobre block explorers ao longo de 6 meses.

## Status Atual (Janeiro 2025)

**Progresso Geral**: 75% concluído
- ✅ Fases 1-3: Completas
- 🔄 Fase 4: Em andamento (artigos científicos)
- ⏳ Fase 5: Planejada

## Cronograma Geral

| Mês | Fase | Atividades Principais | Status |
|-----|------|----------------------|--------|
| 1 | Revisão e Mapeamento | Revisão bibliográfica, mapeamento de explorers | ✅ Concluído |
| 2 | Análise Comparativa | Análise técnica detalhada, benchmarking | ✅ Concluído |
| 3 | Síntese e Framework | Consolidação de achados, desenvolvimento de framework | ✅ Concluído |
| 4-5 | Produção de Artigos | Escrita e revisão de artigos científicos | 🔄 Em andamento |
| 6 | Apresentação | Preparação e defesa do TCC | ⏳ Planejado |

## Mês 1: Revisão e Mapeamento ✅ CONCLUÍDO

**Objetivos**:
- Compreender o estado da arte em block explorers
- Mapear explorers existentes
- Estabelecer base teórica

**Atividades**:
- Revisão sistemática da literatura (IEEE, ACM, arXiv)
- Mapeamento de 12+ explorers principais
- Coleta de dados técnicos e especificações
- Análise inicial de padrões

**Entregas**:
- ✅ Revisão bibliográfica completa
- ✅ Panorama de explorers existentes
- ✅ Base de dados consolidada

**Tempo**: Semanas 1-4

---

## Mês 2: Análise Comparativa ✅ CONCLUÍDO

**Objetivos**:
- Analisar arquiteturas e tecnologias
- Identificar padrões e tendências
- Realizar benchmarking

**Atividades**:
- Análise arquitetural detalhada
- Análise de stacks tecnológicas
- Benchmarking de performance (quando possível)
- Análise de código fonte (open source)

**Entregas**:
- ✅ Análise comparativa completa
- ✅ Taxonomia de block explorers
- ✅ Métricas de performance consolidadas
- ✅ Identificação de padrões dominantes

**Tempo**: Semanas 5-8

---

## Mês 3: Síntese e Framework ✅ CONCLUÍDO

**Objetivos**:
- Sintetizar achados da pesquisa
- Desenvolver framework de avaliação
- Identificar lacunas de pesquisa

**Atividades**:
- Consolidação de dados
- Desenvolvimento de framework de classificação
- Análise de lacunas
- Propostas de inovação

**Entregas**:
- ✅ Framework de avaliação multidimensional
- ✅ Identificação de 5+ lacunas de pesquisa
- ✅ Propostas arquiteturais
- ✅ Whitepaper completo

**Tempo**: Semanas 9-12

---

## Meses 4-5: Produção de Artigos 🔄 EM ANDAMENTO

**Objetivos**:
- Produzir artigos científicos de qualidade
- Submeter para conferências/periódicos
- Documentar conhecimento gerado

**Atividades**:

**Artigo 1** - Survey Paper: ✅ CONCLUÍDO
- ✅ Revisão sistemática e taxonomia
- ✅ Target: ACM Computing Surveys
- ✅ Status: Pronto para submissão

**Artigo 2** - Technical Paper: 🔄 EM ANDAMENTO
- Análise de estratégias de indexação
- Target: IEEE Blockchain Conference

**Artigo 3** - Design Paper: ⏳ PLANEJADO
- Padrões arquiteturais
- Target: ACM Web3 Conference

**Artigo 4** - Empirical Paper (opcional): ⏳ PLANEJADO
- Benchmarking de performance
- Target: IEEE Performance Evaluation

**Artigo 5** - Security Analysis (opcional): ⏳ PLANEJADO
- Vulnerabilidades e mitigações
- Target: IEEE Security & Privacy

**Entregas**:
- ✅ 1 artigo concluído e pronto para submissão
- ✅ Whitepaper desenvolvido (pronto para publicação)
- ✅ Documentação técnica completa
- 🔄 2-4 artigos adicionais em desenvolvimento

**Tempo**: Semanas 13-20

---

## Mês 6: Apresentação e Defesa ⏳ PLANEJADO

**Objetivos**:
- Preparar apresentação final
- Defender TCC
- Publicar resultados

**Atividades**:
- Preparação de slides
- Ensaios de apresentação
- Defesa perante banca
- Publicação de dados e código (se houver)

**Entregas**:
- Apresentação de TCC
- Defesa aprovada
- Repositório GitHub público
- Dataset de pesquisa (se aplicável)

**Tempo**: Semanas 21-24

---

## Métricas de Sucesso

### Publicações
- [x] Whitepaper completo desenvolvido
- [x] Whitepaper publicado oficialmente
- [x] 1 artigo concluído e pronto para submissão
- [ ] 2+ artigos adicionais submetidos
- [ ] 1+ artigo aceito em conferência/periódico

### Pesquisa
- [x] 12+ explorers analisados (análise teórica)
- [ ] 5+ explorers analisados (análise prática)
- [x] Taxonomia completa desenvolvida
- [x] Framework de avaliação validado
- [x] 5+ lacunas de pesquisa identificadas

### Apresentação
- [ ] TCC defendido com sucesso
- [ ] Nota final 8.0+
- [ ] Reconhecimento acadêmico

### Impacto
- [x] Repositório público com documentação
- [x] Dados compartilhados com comunidade
- [ ] Contribuição para literatura acadêmica

---

## Marcos Críticos

**Marco 1** (Fim Mês 1): Base de pesquisa estabelecida ✅ CONCLUÍDO
- ✅ Revisão bibliográfica completa
- ✅ Explorers mapeados
- ✅ Metodologia definida

**Marco 2** (Fim Mês 2): Análise concluída ✅ CONCLUÍDO
- ✅ Padrões identificados
- ✅ Taxonomia desenvolvida
- ✅ Dados consolidados

**Marco 3** (Fim Mês 3): Conhecimento sintetizado ✅ CONCLUÍDO
- ✅ Framework desenvolvido
- ✅ Lacunas identificadas
- ✅ Whitepaper completo

**Marco 4** (Fim Mês 5): Artigos produzidos 🔄 EM ANDAMENTO
- ✅ 1 artigo concluído e pronto para submissão
- ✅ Whitepaper desenvolvido (pronto para publicação)
- ✅ Documentação completa
- 🔄 2-4 artigos adicionais em desenvolvimento

**Marco 5** (Fim Mês 6): Projeto concluído ⏳ PLANEJADO
- ⏳ TCC defendido
- ⏳ Publicações em andamento
- ⏳ Impacto alcançado

---

## Riscos e Mitigações

| Risco | Probabilidade | Impacto | Mitigação |
|-------|---------------|---------|-----------|
| Acesso limitado a dados | Média | Alto | Focar em explorers open source e dados públicos |
| Atraso na revisão bibliográfica | Baixa | Médio | Iniciar imediatamente, definir escopo claro |
| Rejeição de artigos | Alta | Médio | Submeter para múltiplos venues, qualidade alta |
| Complexidade técnica | Média | Médio | Focar em análise documental, evitar implementação complexa |
| Falta de tempo | Média | Alto | Priorizar entregas essenciais, buffer de tempo |

---

## Recursos Necessários

### Humanos
- Pesquisador principal: 20h/semana
- Orientador: 2h/semana (reuniões)
- Revisores: conforme necessário

### Técnicos
- Computador com internet
- Acesso a bases acadêmicas (IEEE, ACM)
- Ferramentas gratuitas (análise, documentação)

### Financeiros
- Custo zero (uso de recursos gratuitos)
- Acesso institucional a bases de dados

---

## Contingências

### Se houver atraso
- Priorizar artigos principais (Survey + Technical)
- Reduzir escopo de artigos secundários
- Focar em qualidade sobre quantidade

### Se houver dificuldade técnica
- Aumentar foco em análise documental
- Utilizar dados públicos disponíveis
- Buscar suporte de especialistas

### Se artigos forem rejeitados
- Revisar com base em feedback
- Resubmeter para venues alternativos
- Publicar em repositórios abertos (arXiv)

---

## Próximos Passos (Janeiro 2025)

### Imediato (Próximas 2 semanas)
- [ ] Submeter Artigo 1 para ACM Computing Surveys
- [ ] Publicar Whitepaper oficialmente (GitHub, arXiv, ou plataforma acadêmica)
- [ ] **NOVA FASE**: Análise Prática de Repositórios Open Source
- [ ] Preparar apresentação para orientador

### Análise Prática de Repositórios (Nova Fase)

#### Objetivos da Análise Prática
- [ ] **Clonar repositórios** dos explorers open source identificados
- [ ] **Testar funcionalidades** em ambiente local
- [ ] **Analisar stacks tecnológicas** reais (não apenas documentação)
- [ ] **Validar métricas** de performance com testes práticos
- [ ] **Documentar descobertas** para enriquecer o whitepaper

#### Explorers Open Source para Análise

**Prioridade Alta (Análise Completa)**:
- [ ] **BlockScout** (Ethereum) - https://github.com/blockscout/blockscout
  - **Motivo**: Maior explorer open source Ethereum
  - **Stack**: Elixir, Phoenix, PostgreSQL
  - **Foco**: Arquitetura de microserviços

- [ ] **Mempool.space** (Bitcoin) - https://github.com/mempool/mempool
  - **Motivo**: Explorer Bitcoin mais popular
  - **Stack**: TypeScript, Node.js, MySQL
  - **Foco**: Performance e UX

**Prioridade Média (Análise Parcial)**:
- [ ] **Big Dipper** (Cosmos) - https://github.com/forbole/big-dipper-2.0-cosmos
  - **Stack**: Next.js, TypeScript, GraphQL
  - **Foco**: Interface moderna

- [ ] **Subscan** (Polkadot) - https://github.com/itering/subscan
  - **Stack**: PHP, Laravel, MySQL
  - **Foco**: Arquitetura monolítica

**Prioridade Baixa (Análise Rápida)**:
- [ ] **Solana Explorer** (Solana) - https://github.com/solana-labs/explorer
  - **Stack**: React, TypeScript
  - **Foco**: Performance em alta frequência

#### Atividades Técnicas Planejadas
- [ ] **Setup de Ambiente**: Docker, dependências, configurações
- [ ] **Análise de Código**: Arquitetura, padrões, tecnologias
- [ ] **Testes de Performance**: Load testing, métricas reais
- [ ] **Documentação**: Screenshots, logs, descobertas
- [ ] **Comparação**: Dados teóricos vs práticos

#### Metodologia de Análise Prática

**Fase 1: Setup e Configuração (Semana 1)**
- [ ] Clonar repositórios dos 5 explorers open source
- [ ] Configurar ambiente de desenvolvimento (Docker, dependências)
- [ ] Documentar processo de setup e dificuldades encontradas
- [ ] Criar script de automação para setup

**Fase 2: Análise Arquitetural (Semana 2)**
- [ ] Mapear estrutura de diretórios e arquivos
- [ ] Identificar tecnologias utilizadas (package.json, requirements.txt, etc.)
- [ ] Analisar padrões de código e arquitetura
- [ ] Documentar diferenças entre documentação e implementação real

**Fase 3: Testes Funcionais (Semana 3)**
- [ ] Executar explorers em ambiente local
- [ ] Testar funcionalidades principais (busca, visualização, APIs)
- [ ] Medir performance básica (tempo de resposta, uso de memória)
- [ ] Documentar bugs, limitações e pontos fortes

**Fase 4: Análise Comparativa (Semana 4)**
- [ ] Comparar dados práticos com análise teórica do whitepaper
- [ ] Identificar discrepâncias entre documentação e realidade
- [ ] Validar métricas de performance com testes reais
- [ ] Atualizar whitepaper com descobertas práticas

#### Entregas da Análise Prática
- [ ] **Relatório Técnico**: Análise detalhada de cada explorer
- [ ] **Scripts de Setup**: Automação para configuração
- [ ] **Métricas Reais**: Dados de performance coletados
- [ ] **Whitepaper Atualizado**: Versão 2.1 com dados práticos
- [ ] **Artigo Técnico**: Base para Artigo 2 com análise prática

#### Recursos Necessários para Análise Prática

**Hardware**:
- [ ] **CPU**: Mínimo 8 cores (recomendado 16 cores)
- [ ] **RAM**: Mínimo 16GB (recomendado 32GB)
- [ ] **Storage**: Mínimo 500GB SSD (para blockchain data)
- [ ] **Rede**: Conexão estável para sync de blockchain

**Software**:
- [ ] **Docker & Docker Compose**: Para containerização
- [ ] **Node.js**: Versão 18+ para frontend
- [ ] **Python**: Versão 3.9+ para scripts de análise
- [ ] **Git**: Para clonar repositórios
- [ ] **PostgreSQL**: Para análise de dados
- [ ] **Redis**: Para cache e performance testing

**Blockchain Nodes** (Opcional):
- [ ] **Ethereum Node**: Geth ou Erigon (para BlockScout)
- [ ] **Bitcoin Node**: Bitcoin Core (para Mempool.space)
- [ ] **Cosmos Node**: Cosmos SDK (para Big Dipper)
- [ ] **Polkadot Node**: Substrate (para Subscan)
- [ ] **Solana Node**: Solana Labs (para Solana Explorer)

**Ferramentas de Análise**:
- [ ] **Apache JMeter**: Load testing
- [ ] **Prometheus + Grafana**: Métricas e monitoramento
- [ ] **SonarQube**: Análise de qualidade de código
- [ ] **GitHub CLI**: Automação de repositórios
- [ ] **VS Code**: IDE com extensões para análise

### Curto Prazo (Próximos 2 meses)
- [ ] Completar Artigo 2 e submeter para IEEE Blockchain Conference
- [ ] Desenvolver Artigo 3 (Design Paper)
- [ ] Preparar estrutura da defesa TCC

### Médio Prazo (Próximos 3 meses)
- [ ] Finalizar todos os artigos planejados
- [ ] Preparar apresentação final do TCC
- [ ] Organizar defesa perante banca

### Longo Prazo (Próximos 6 meses)
- [ ] Defender TCC com sucesso
- [ ] Publicar resultados em conferências
- [ ] Estabelecer colaborações acadêmicas

---

**Versão**: 2.0  
**Atualização**: Janeiro 2025  
**Status**: 75% concluído - Fase 4 em andamento